{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CS263_RoBERTA.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rsWUcIFJ8CAp",
        "colab_type": "text"
      },
      "source": [
        "Mounting Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q1A6tOerXST0",
        "colab_type": "code",
        "outputId": "d63e912e-591e-48ca-f3c6-125cec336f78",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd '/content/drive/My Drive/CS263_Project/'"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n",
            "/content/drive/My Drive/CS263_Project\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "urxdiTR88JDy",
        "colab_type": "text"
      },
      "source": [
        "Loading all datasets from drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lcAEcWu6ZolC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv(r\"all_data.csv\")\n",
        "test_set = pd.read_csv(r\"test_set.csv\")\n",
        "sentiment_data = pd.read_csv(r\"sentiment.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0jVqda3S8ace",
        "colab_type": "code",
        "outputId": "96b7a207-3773-42c8-fd89-4684640b3e88",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 666
        }
      },
      "source": [
        "!pip install torch\n",
        "!pip install transformers"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (1.5.0+cu101)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch) (1.18.4)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch) (0.16.0)\n",
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/48/35/ad2c5b1b8f99feaaf9d7cdadaeef261f098c6e1a6a2935d4d07662a6b780/transformers-2.11.0-py3-none-any.whl (674kB)\n",
            "\u001b[K     |████████████████████████████████| 675kB 9.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Collecting tokenizers==0.7.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/e5/a26eb4716523808bb0a799fcfdceb6ebf77a18169d9591b2f46a9adb87d9/tokenizers-0.7.0-cp36-cp36m-manylinux1_x86_64.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 17.6MB/s \n",
            "\u001b[?25hCollecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/68/e5/0366f50a00db181f4b7f3bdc408fc7c4177657f5bf45cb799b79fb4ce15c/sentencepiece-0.1.92-cp36-cp36m-manylinux1_x86_64.whl (1.2MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2MB 37.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 45.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.4.5.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (1.12.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.15.1)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893260 sha256=e850b61cc1e8adfd47543c9fdce3ccbfebee98d72e2311d689ff4c2dde89672b\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: tokenizers, sentencepiece, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.43 sentencepiece-0.1.92 tokenizers-0.7.0 transformers-2.11.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YkG7aoqf8hbk",
        "colab_type": "text"
      },
      "source": [
        "Function for BERT Vectorization is defined"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iFk5zLSv8fuT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import transformers as ppb # pytorch transformers\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "def vectorizeBERT(df, bert_type = \"bert\"):\n",
        "\n",
        "  if bert_type == \"distil\":\n",
        "    model_class, tokenizer_class, pretrained_weights = (ppb.DistilBertModel, ppb.DistilBertTokenizer, 'distilbert-base-uncased')\n",
        "  elif bert_type == \"roberta\":\n",
        "    model_class, tokenizer_class, pretrained_weights = (ppb.RobertaModel, ppb.RobertaTokenizer, 'roberta-base')\n",
        "  else:\n",
        "    model_class, tokenizer_class, pretrained_weights = (ppb.BertModel, ppb.BertTokenizer, 'bert-base-uncased')\n",
        "\n",
        "  # Load pretrained model/tokenizer\n",
        "  tokenizer = tokenizer_class.from_pretrained(pretrained_weights)\n",
        "  model = model_class.from_pretrained(pretrained_weights)\n",
        "\n",
        "  tokenized = df[\"text\"].apply((lambda x: tokenizer.encode(x, add_special_tokens=True)))\n",
        "\n",
        "  # padding step\n",
        "  max_len = 0\n",
        "  for i in tokenized.values:\n",
        "    if len(i) > max_len:\n",
        "      max_len = len(i)\n",
        "\n",
        "  padded = np.array([i + [0]*(max_len-len(i)) for i in tokenized.values])\n",
        "\n",
        "  attention_mask = np.where(padded != 0, 1, 0)\n",
        "  attention_mask.shape\n",
        "\n",
        "  input_ids = torch.tensor(np.array(padded))\n",
        "  attention_mask = torch.tensor(attention_mask)\n",
        "\n",
        "  with torch.no_grad():\n",
        "    last_hidden_states = model(input_ids, attention_mask=attention_mask)\n",
        "  # Slice the output for the first position for all the sequences, take all hidden unit outputs\n",
        "  features = last_hidden_states[0][:,0,:].numpy()\n",
        "\n",
        "  return features\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lkxA8eWS_Xd1",
        "colab_type": "text"
      },
      "source": [
        "Function for obtaining sentiment score using sentiment data is defined"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Mof6wXn-z-E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random\n",
        "import pickle\n",
        "def obtain_sentiment_classifier(sentiment_data,data_select=4000,bert_type=\"bert\"):\n",
        "\n",
        "  #Randomly selecting a small portion of sentiment data, since the dataset is too big\n",
        "  rand_ind = random.sample(range(sentiment_data.shape[0]),data_select)\n",
        "  sentiment=sentiment_data.iloc[rand_ind]\n",
        "  # Build the sentiment model\n",
        "  features = vectorizeBERT(sentiment,bert_type=bert_type)\n",
        "  features_ds = pd.DataFrame(features)\n",
        "  labels = sentiment[\"label\"]\n",
        "  train_features, test_features, train_labels, test_labels = train_test_split(features_ds, labels)\n",
        "  #Logistic Regression classifier for sentiment analysis\n",
        "  lr_clf_sentiment = LogisticRegression(max_iter=5000)\n",
        "  lr_clf_sentiment.fit(train_features, train_labels)\n",
        "  #Calculate score of logistic regression classifier on sentiment data\n",
        "  sent_accuracy = lr_clf_sentiment.score(test_features, test_labels)\n",
        "  print(\"The accuracy of Logistic Regression classifier on sentiment data is: \",sent_accuracy)\n",
        "  pickle.dump(lr_clf_sentiment, open(\"sentiment_model\", 'wb'))\n",
        "  return lr_clf_sentiment"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2G93tK-j8xh_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4e941ea5-dac0-4833-f8c1-69c131b26f59"
      },
      "source": [
        "# Build the cognitive distortion model\n",
        "# M x N matrix\n",
        "import time\n",
        "start_time = time.time()\n",
        "features = vectorizeBERT(df,bert_type=\"roberta\")\n",
        "print(\"Time taken is:\",time.time()-start_time)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Time taken is: 118.46877193450928\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C47k6CTXAS64",
        "colab_type": "text"
      },
      "source": [
        "Creating training dataset with features and sentiment scores"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GaB1h_A58yWS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labels = df[\"label\"]\n",
        "features_df = pd.DataFrame(features)\n",
        "lr_clf_sentiment = obtain_sentiment_classifier(sentiment_data,data_select=4000,bert_type=\"roberta\")\n",
        "#lr_clf_sentiment = pickle.load(open(\"sentiment_model_roberta\",\"rb\"))\n",
        "sentiment_score = lr_clf_sentiment.predict_log_proba(features)[:,0]\n",
        "features_df[\"sentiment_score\"] = sentiment_score\n",
        "features_df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aEiWSJj9Ad_g",
        "colab_type": "text"
      },
      "source": [
        "Evaluating  Logistic Regression Classifier on the features obtained"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rc6tW4NFDxBE",
        "colab_type": "code",
        "outputId": "4f680012-db95-43ed-9357-fbe5c83d8b7b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "train_features, test_features, train_labels, test_labels = train_test_split(features_df, labels)\n",
        "\n",
        "lr_clf = LogisticRegression(max_iter=5000)\n",
        "lr_clf.fit(train_features, train_labels)\n",
        "score = lr_clf.score(test_features, test_labels)\n",
        "print(\"Accuracy without scaling is: \",score)\n",
        "from sklearn import preprocessing\n",
        "# Scale\n",
        "scaled_train_features = preprocessing.scale(train_features)\n",
        "scaled_test_features = preprocessing.scale(test_features)\n",
        "\n",
        "lr_clf_scaled = LogisticRegression(max_iter=5000)\n",
        "lr_clf_scaled.fit(scaled_train_features, train_labels)\n",
        "score = lr_clf_scaled.score(scaled_test_features, test_labels)\n",
        "print(\"Accuracy with scaling is: \",score)\n"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy without scaling is:  0.8016877637130801\n",
            "Accuracy with scaling is:  0.7932489451476793\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dUyYrzlkNR4I",
        "colab_type": "text"
      },
      "source": [
        "As we can see from above scaling the features barely affects the accuracy and hence we drop scaling moving forward"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lkPSZ-JaArNj",
        "colab_type": "text"
      },
      "source": [
        "Evaluating Logistic Regression Classifier on a Random Test Set not a part of the augmented dataset used for training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oOgZYkAQ10RA",
        "colab_type": "code",
        "outputId": "33bd015c-3bf2-483c-b045-a1659d38313d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "def unbiased_test_score(test_set,lr_clf_sentiment,model=lr_clf,return_mode=False):\n",
        "  test = vectorizeBERT(test_set,bert_type=\"roberta\")\n",
        "  test_l = test_set[\"label\"]\n",
        "  test_score = lr_clf_sentiment.predict_log_proba(test)[:,0]\n",
        "  test_df = pd.DataFrame(test)\n",
        "  test_df[\"sentiment_score\"] = test_score\n",
        "  print(\"Score for Random unbiased Dataset\",model.score(test_df, test_l))\n",
        "  if return_mode:\n",
        "    return model.predict(test_df),model.predict_proba(test_df)[:,0],test_l\n",
        "\n",
        "unbiased_test_score(test_set,lr_clf_sentiment,lr_clf)\n"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Score for Random unbiased Dataset 0.58\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B1LVSgyPQcHV",
        "colab_type": "text"
      },
      "source": [
        "Evaluating Linear SVM on a Random Test Set not a part of the augmented dataset used for training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PucNd_ctD_pt",
        "colab_type": "code",
        "outputId": "12177581-675a-4dc5-a5f6-b5b934b1a7a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "from sklearn.svm import SVC\n",
        "our_svm_model = SVC(kernel = \"linear\",C=1000,random_state=1)\n",
        "our_svm_model.fit(train_features, train_labels)\n",
        "biased_Score = our_svm_model.score(test_features, test_labels)\n",
        "print(\"Biased score for SVM is: \",biased_Score)\n",
        "unbiased_test_score(test_set,lr_clf_sentiment,our_svm_model)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Biased score for SVM is:  0.759493670886076\n",
            "Score for Random unbiased Dataset 0.64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4cA76JaEps6C",
        "colab_type": "text"
      },
      "source": [
        "Evaluating RandomForestClassifier on a Random Test Set not a part of the augmented dataset used for training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jwchE8yCpsO9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "2393234c-2463-4e74-c15d-4c0af1679af6"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "modelRFC = RandomForestClassifier()\n",
        "modelRFC.fit(train_features, train_labels)\n",
        "biased_Score = modelRFC.score(test_features, test_labels)\n",
        "print(\"Biased score for RandomForestClassifier is: \",biased_Score)\n",
        "unbiased_test_score(test_set,lr_clf_sentiment,modelRFC)\n"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Biased score for RandomForestClassifier is:  0.7383966244725738\n",
            "Score for Random unbiased Dataset 0.46\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "atbu5dAYQhgw",
        "colab_type": "text"
      },
      "source": [
        "Evaluating XGBoostClassifier on a Random Test Set not a part of the augmented dataset used for training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sXvgDId-NqIq",
        "colab_type": "code",
        "outputId": "fb9adae3-1266-4fc2-98ca-49e45a70274c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "from xgboost import XGBClassifier\n",
        "modelXGB = XGBClassifier()\n",
        "modelXGB.fit(train_features, train_labels)\n",
        "biased_Score = modelXGB.score(test_features, test_labels)\n",
        "print(\"Biased score for XGBoostClassifier is: \",biased_Score)\n",
        "unbiased_test_score(test_set,lr_clf_sentiment,modelXGB)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Biased score for XGBoostClassifier is:  0.7679324894514767\n",
            "Score for Random unbiased Dataset 0.6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OvJVY9nOBbiQ",
        "colab_type": "code",
        "outputId": "2d253513-22bd-4185-8183-ad2f9b5cd812",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 813
        }
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "pipe = Pipeline([('classifier' , RandomForestClassifier())])\n",
        "\n",
        "# Create param grid.\n",
        "\n",
        "param_grid = [\n",
        "    {'classifier' : [LogisticRegression(max_iter=5000)],\n",
        "     'classifier__penalty' : ['l1', 'l2'],\n",
        "    'classifier__C' : np.logspace(-4, 4, 20),\n",
        "    'classifier__solver' : ['liblinear','lbfgs']},\n",
        "    {'classifier' : [RandomForestClassifier()],\n",
        "    'classifier__n_estimators' : list(range(10,101,10)),\n",
        "    'classifier__max_features' : list(range(6,32,5))},\n",
        "    {'classifier' : [SVC(probability=True)],\n",
        "    'classifier__C' : np.logspace(-4, 4, 20),\n",
        "    'classifier__kernel' : ['linear','rbf']},\n",
        "    {'classifier' : [XGBClassifier()]}\n",
        "]\n",
        "\n",
        "# Create grid search object\n",
        "\n",
        "clf = GridSearchCV(pipe, param_grid = param_grid, cv = 5, verbose=True, n_jobs=-1)\n",
        "\n",
        "\n",
        "best_clf = clf.fit(train_features, train_labels)\n",
        "\n",
        "\n",
        "print('Best parameters are: ',best_clf.best_params_)\n",
        "print('Best score is: ',best_clf.best_score_)\n",
        "\n",
        "pd.DataFrame(best_clf.cv_results_)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 181 candidates, totalling 905 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done 174 tasks      | elapsed:    6.7s\n",
            "[Parallel(n_jobs=-1)]: Done 394 tasks      | elapsed:  1.9min\n",
            "[Parallel(n_jobs=-1)]: Done 644 tasks      | elapsed:  2.9min\n",
            "[Parallel(n_jobs=-1)]: Done 905 out of 905 | elapsed:  6.5min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Best parameters are:  {'classifier': LogisticRegression(C=11.288378916846883, class_weight=None, dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=5000, multi_class='auto', n_jobs=None, penalty='l2',\n",
            "                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,\n",
            "                   warm_start=False), 'classifier__C': 11.288378916846883, 'classifier__penalty': 'l2', 'classifier__solver': 'liblinear'}\n",
            "Best score is:  0.812922288978627\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean_fit_time</th>\n",
              "      <th>std_fit_time</th>\n",
              "      <th>mean_score_time</th>\n",
              "      <th>std_score_time</th>\n",
              "      <th>param_classifier</th>\n",
              "      <th>param_classifier__C</th>\n",
              "      <th>param_classifier__penalty</th>\n",
              "      <th>param_classifier__solver</th>\n",
              "      <th>param_classifier__max_features</th>\n",
              "      <th>param_classifier__n_estimators</th>\n",
              "      <th>param_classifier__kernel</th>\n",
              "      <th>params</th>\n",
              "      <th>split0_test_score</th>\n",
              "      <th>split1_test_score</th>\n",
              "      <th>split2_test_score</th>\n",
              "      <th>split3_test_score</th>\n",
              "      <th>split4_test_score</th>\n",
              "      <th>mean_test_score</th>\n",
              "      <th>std_test_score</th>\n",
              "      <th>rank_test_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.042441</td>\n",
              "      <td>0.012179</td>\n",
              "      <td>0.004140</td>\n",
              "      <td>0.001242</td>\n",
              "      <td>LogisticRegression(C=11.288378916846883, class...</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>l1</td>\n",
              "      <td>liblinear</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>{'classifier': LogisticRegression(C=11.2883789...</td>\n",
              "      <td>0.510490</td>\n",
              "      <td>0.507042</td>\n",
              "      <td>0.507042</td>\n",
              "      <td>0.514085</td>\n",
              "      <td>0.514085</td>\n",
              "      <td>0.510549</td>\n",
              "      <td>0.003150</td>\n",
              "      <td>132</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.005887</td>\n",
              "      <td>0.002895</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>LogisticRegression(C=11.288378916846883, class...</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>l1</td>\n",
              "      <td>lbfgs</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>{'classifier': LogisticRegression(C=11.2883789...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>164</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.031371</td>\n",
              "      <td>0.000876</td>\n",
              "      <td>0.003642</td>\n",
              "      <td>0.000152</td>\n",
              "      <td>LogisticRegression(C=11.288378916846883, class...</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>l2</td>\n",
              "      <td>liblinear</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>{'classifier': LogisticRegression(C=11.2883789...</td>\n",
              "      <td>0.510490</td>\n",
              "      <td>0.507042</td>\n",
              "      <td>0.507042</td>\n",
              "      <td>0.514085</td>\n",
              "      <td>0.514085</td>\n",
              "      <td>0.510549</td>\n",
              "      <td>0.003150</td>\n",
              "      <td>132</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.033032</td>\n",
              "      <td>0.004857</td>\n",
              "      <td>0.004789</td>\n",
              "      <td>0.002800</td>\n",
              "      <td>LogisticRegression(C=11.288378916846883, class...</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>l2</td>\n",
              "      <td>lbfgs</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>{'classifier': LogisticRegression(C=11.2883789...</td>\n",
              "      <td>0.510490</td>\n",
              "      <td>0.507042</td>\n",
              "      <td>0.507042</td>\n",
              "      <td>0.514085</td>\n",
              "      <td>0.514085</td>\n",
              "      <td>0.510549</td>\n",
              "      <td>0.003150</td>\n",
              "      <td>132</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.033109</td>\n",
              "      <td>0.014717</td>\n",
              "      <td>0.004551</td>\n",
              "      <td>0.002109</td>\n",
              "      <td>LogisticRegression(C=11.288378916846883, class...</td>\n",
              "      <td>0.000263665</td>\n",
              "      <td>l1</td>\n",
              "      <td>liblinear</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>{'classifier': LogisticRegression(C=11.2883789...</td>\n",
              "      <td>0.510490</td>\n",
              "      <td>0.507042</td>\n",
              "      <td>0.507042</td>\n",
              "      <td>0.514085</td>\n",
              "      <td>0.514085</td>\n",
              "      <td>0.510549</td>\n",
              "      <td>0.003150</td>\n",
              "      <td>132</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>176</th>\n",
              "      <td>1.282536</td>\n",
              "      <td>0.049604</td>\n",
              "      <td>0.046060</td>\n",
              "      <td>0.001469</td>\n",
              "      <td>SVC(C=1.0, break_ties=False, cache_size=200, c...</td>\n",
              "      <td>3792.69</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>linear</td>\n",
              "      <td>{'classifier': SVC(C=1.0, break_ties=False, ca...</td>\n",
              "      <td>0.811189</td>\n",
              "      <td>0.732394</td>\n",
              "      <td>0.809859</td>\n",
              "      <td>0.774648</td>\n",
              "      <td>0.838028</td>\n",
              "      <td>0.793224</td>\n",
              "      <td>0.036475</td>\n",
              "      <td>32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>177</th>\n",
              "      <td>1.461166</td>\n",
              "      <td>0.102012</td>\n",
              "      <td>0.052220</td>\n",
              "      <td>0.001481</td>\n",
              "      <td>SVC(C=1.0, break_ties=False, cache_size=200, c...</td>\n",
              "      <td>3792.69</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>rbf</td>\n",
              "      <td>{'classifier': SVC(C=1.0, break_ties=False, ca...</td>\n",
              "      <td>0.825175</td>\n",
              "      <td>0.746479</td>\n",
              "      <td>0.823944</td>\n",
              "      <td>0.781690</td>\n",
              "      <td>0.838028</td>\n",
              "      <td>0.803063</td>\n",
              "      <td>0.034077</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>178</th>\n",
              "      <td>1.289373</td>\n",
              "      <td>0.053362</td>\n",
              "      <td>0.046074</td>\n",
              "      <td>0.001374</td>\n",
              "      <td>SVC(C=1.0, break_ties=False, cache_size=200, c...</td>\n",
              "      <td>10000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>linear</td>\n",
              "      <td>{'classifier': SVC(C=1.0, break_ties=False, ca...</td>\n",
              "      <td>0.811189</td>\n",
              "      <td>0.732394</td>\n",
              "      <td>0.809859</td>\n",
              "      <td>0.774648</td>\n",
              "      <td>0.838028</td>\n",
              "      <td>0.793224</td>\n",
              "      <td>0.036475</td>\n",
              "      <td>32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>179</th>\n",
              "      <td>1.454754</td>\n",
              "      <td>0.133681</td>\n",
              "      <td>0.051749</td>\n",
              "      <td>0.001097</td>\n",
              "      <td>SVC(C=1.0, break_ties=False, cache_size=200, c...</td>\n",
              "      <td>10000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>rbf</td>\n",
              "      <td>{'classifier': SVC(C=1.0, break_ties=False, ca...</td>\n",
              "      <td>0.825175</td>\n",
              "      <td>0.746479</td>\n",
              "      <td>0.823944</td>\n",
              "      <td>0.781690</td>\n",
              "      <td>0.838028</td>\n",
              "      <td>0.803063</td>\n",
              "      <td>0.034077</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>180</th>\n",
              "      <td>4.554421</td>\n",
              "      <td>0.571913</td>\n",
              "      <td>0.019969</td>\n",
              "      <td>0.003416</td>\n",
              "      <td>XGBClassifier(base_score=0.5, booster='gbtree'...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>{'classifier': XGBClassifier(base_score=0.5, b...</td>\n",
              "      <td>0.713287</td>\n",
              "      <td>0.795775</td>\n",
              "      <td>0.774648</td>\n",
              "      <td>0.767606</td>\n",
              "      <td>0.788732</td>\n",
              "      <td>0.768009</td>\n",
              "      <td>0.029118</td>\n",
              "      <td>57</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>181 rows × 20 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     mean_fit_time  std_fit_time  ...  std_test_score  rank_test_score\n",
              "0         0.042441      0.012179  ...        0.003150              132\n",
              "1         0.005887      0.002895  ...             NaN              164\n",
              "2         0.031371      0.000876  ...        0.003150              132\n",
              "3         0.033032      0.004857  ...        0.003150              132\n",
              "4         0.033109      0.014717  ...        0.003150              132\n",
              "..             ...           ...  ...             ...              ...\n",
              "176       1.282536      0.049604  ...        0.036475               32\n",
              "177       1.461166      0.102012  ...        0.034077               15\n",
              "178       1.289373      0.053362  ...        0.036475               32\n",
              "179       1.454754      0.133681  ...        0.034077               15\n",
              "180       4.554421      0.571913  ...        0.029118               57\n",
              "\n",
              "[181 rows x 20 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GGhCcK_7UC-a",
        "colab_type": "code",
        "outputId": "38fca180-3633-414b-ec09-0672aea569f0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "unbiased_test_score(test_set,lr_clf_sentiment,best_clf)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Score for Random unbiased Dataset 0.6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z_Btju4uR1Jg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import roc_curve\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "def evaluation_parameters(y_test,y_pred):\n",
        "  con_mat = confusion_matrix(y_test,y_pred)\n",
        "  tn, fp, fn, tp = con_mat.ravel()\n",
        "  precision = tp/(tp+fp)\n",
        "  recall = tp/(tp+fn)\n",
        "  f1 = 2*precision*recall/(precision+recall)\n",
        "  acc = (tp+tn)/(tn+fn+fp+tp)\n",
        "  print(\"Confusion Matrix:\")\n",
        "  print(con_mat)\n",
        "  print(\"The precision is: \",precision)\n",
        "  print(\"The recall is: \",recall)\n",
        "  print(\"The f1_score is: \",f1)\n",
        "  print(\"The accuracy is: \",acc)\n",
        "\n",
        "def plot_roc(y_test,y_score):\n",
        "  fpr,tpr,thresh=roc_curve(y_test,y_score)\n",
        "  plt.plot(fpr,tpr)\n",
        "  plt.grid()\n",
        "  plt.ylim(0,1.1)\n",
        "  print(\"The roc score is \",roc_auc_score(y_test,y_score))\n",
        "  plt.xlabel(\"Specificity\")\n",
        "  plt.ylabel(\"Sensitivity\")\n",
        "  plt.title(\"ROC Curve\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MeignRGpSHHk",
        "colab_type": "code",
        "outputId": "ba3552ec-7ca0-44b3-c46a-2655efd7fb36",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y_pred,y_score,y_test = unbiased_test_score(test_set,lr_clf_sentiment,best_clf,True)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Score for Random unbiased Dataset 0.6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xRTw_2wr4bBy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "pickle.dump(best_clf, open(\"best_clf_roberta\", 'wb'))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ET29ddLYFUi",
        "colab_type": "code",
        "outputId": "46ebae85-dd36-480a-d3f9-e993ea9ce4cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "evaluation_parameters(y_test,y_pred)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion Matrix:\n",
            "[[13 11]\n",
            " [ 9 17]]\n",
            "The precision is:  0.6071428571428571\n",
            "The recall is:  0.6538461538461539\n",
            "The f1_score is:  0.6296296296296297\n",
            "The accuracy is:  0.6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qerybn2JYKtp",
        "colab_type": "code",
        "outputId": "237e6f72-e05e-4146-c39f-4f1a54c68d1a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        }
      },
      "source": [
        "plot_roc(y_test,y_score)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The roc score is  0.3205128205128205\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}